/*
 * -------------------------------------------------
 *  nf-core/ampliseq Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

// Global default params, used in configs
params {
  input             = false
  pacbio            = false
  FW_primer         = false
  RV_primer         = false 
  classifier        = ""
  metadata          = ""

  // Defines all parameters that are independent of a test run
  extension         = "/*_R{1,2}_001.fastq.gz"
  help              = false
  publish_dir_mode  = 'copy'
  trunc_qmin        = 25
  trunc_rmin        = 0.75
  trunclenf         = false
  trunclenr         = false
  max_ee            = 2
  max_len           = "Inf"
  min_len           = 50
  metadata_category = ""
  double_primer     = false
  retain_untrimmed  = false
  exclude_taxa      = "mitochondria,chloroplast"
  min_frequency     = 1
  min_samples       = 1
  multiple_sequencing_runs = false
  single_end        = false
  sample_inference  = "independent"
  illumina_pe_its   = false
  concatenate_reads = false
  cut_its           = false

  //skipping steps
  skip_qiime        = false
  skip_fastqc       = false
  skip_alpha_rarefaction = false
  skip_abundance_tables = false
	skip_barplot      = false
	skip_taxonomy     = false
	skip_alpha_rarefaction = false
	skip_diversity_indices = false
	skip_ancom        = false
  skip_multiqc      = false

  //Database specific parameters
  dada_ref_taxonomy = "silva=138"
  qiime_ref_taxonomy = ""

  // Boilerplate options
  outdir            = './results'
  enable_conda      = false
  multiqc_config    = ''
  multiqc_title     = ''
  email             = ''
  email_on_fail     = ''
  max_multiqc_email_size = 25.MB
  plaintext_email   = false
  monochrome_logs   = false
  help              = false
  tracedir          = "${params.outdir}/pipeline_info"
  custom_config_version = 'master'
  custom_config_base = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
  hostnames         = false
  config_profile_name = null
  config_profile_description = false
  config_profile_contact = false
  config_profile_url = false
  singularity_pull_docker_container = false
  validate_params   = true
  show_hidden_params = false
  schema_ignore_params = 'dada_ref_databases,qiime_ref_databases,modules'

  // Defaults only, expecting to be overwritten
  max_memory        = 128.GB
  max_cpus          = 16
  max_time          = 240.h

}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Load ref_databases.config for all pipelines
includeConfig 'conf/ref_databases.config'
 
// Load nf-core custom profiles from different Institutions
try {
  includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
  System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}
// Load nf-core/ampliseq custom profiles from different Institutions
try {
  includeConfig "${params.custom_config_base}/pipeline/ampliseq.config"
} catch (Exception e) {
  System.err.println("WARNING: Could not load nf-core/config/ampliseq profiles: ${params.custom_config_base}/pipeline/ampliseq.config")
}

profiles {
  conda {
    docker.enabled = false
    singularity.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = false
  }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  conda { params.enable_conda = true }
  docker {
    docker.enabled = true
    singularity.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = false
    // Avoid this error:
    //   WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
    // Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
    // once this is established and works well, nextflow might implement this behavior as new default.
    docker.runOptions = '-u \$(id -u):\$(id -g)'
  }
  singularity {
    docker.enabled = false
    singularity.enabled = true
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = false
    singularity.autoMounts = true
  }
  podman {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = true
    shifter.enabled = false
    charliecloud.enabled = false
  }
  shifter {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = false
    shifter.enabled = true
    charliecloud.enabled = false
  }
  charliecloud {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = true
  }
  test { includeConfig 'conf/test.config' }
  test_multi { includeConfig 'conf/test_multi.config' }
  test_doubleprimers { includeConfig 'conf/test_doubleprimers.config' }
  test_pacbio_its { includeConfig 'conf/test_pacbio_its.config' }
  test_full { includeConfig 'conf/test_full.config' }
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
  PYTHONNOUSERSITE = 1
  R_PROFILE_USER = "/.Rprofile"
  R_ENVIRON_USER = "/.Renviron"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag_${trace_timestamp}.svg"
}

manifest {
  name = 'nf-core/ampliseq'
  author = 'Daniel Straub, Alexander Peltzer'
  homePage = 'https://github.com/nf-core/ampliseq'
  description = '16S rRNA amplicon sequencing analysis workflow using QIIME2'
  mainScript = 'main.nf'
  nextflowVersion = '!>=21.04.0'
  version = '2.0.0dev'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
